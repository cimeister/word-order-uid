#!/bin/bash
 
# Job details
TIME=04:00  # HH:MM (default: 04:00, max: 240:00)
NUM_GPUS=0  # GPUs per node
NUM_CPUS=1  # Number of cores (default: 1)
CPU_RAM=2048  # RAM for each core (default: 1024)
 
# Load modules
module load gcc/6.3.0
module load python_gpu/3.8.5 hdf5 eth_proxy
module load geos
module load libspatialindex

# DATA_DIR="../../data/wiki40b-txt-parsed"
# RESULTS_DIR="../../data/wiki40b-txt-cf" 

PARSE_DIR="../../data/wiki40b-txt-parsed-v2"
DATA_DIR="../../data/wiki40b-txt-cf-v3"
RESULTS_DIR="../coref" 

partitions=("train")

mkdir -p $RESULTS_DIR
mkdir -p logs_cf_data

for D in $(find $DATA_DIR -mindepth 1 -maxdepth 1 -type d)
do
    lang=$(basename $D)
    echo $lang 
    for M in $(find $DATA_DIR/$lang -mindepth 1 -maxdepth 1 -type d)
    do
        model=$(basename $M)
        echo $model
        for partition in "${partitions[@]}"
        do
            bsub -W $TIME \
                -n $NUM_CPUS \
                -R "rusage[mem=${CPU_RAM},ngpus_excl_p=${NUM_GPUS}]" \
                -o logs_cf_data/dep_len_${lang}_$model.out \
                "python ../apply_counterfactual_grammar.py --coref_analysis --filename $PARSE_DIR/$lang.$partition.conllu --model $model > $RESULTS_DIR/$lang-$model-$partition.txt"
        done
    done
done
